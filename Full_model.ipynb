{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda-python\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import matplotlib.cm as cm\n",
    "from scipy.misc import imresize\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import scipy.io as io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction and Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extraction(path):\n",
    "    data_l, data_r, data_all = [], [], []\n",
    "    nor_data = io.loadmat(path)\n",
    "    temp = nor_data['data']\n",
    "    r = temp['right']\n",
    "    l = temp['left']\n",
    "    r_temp = r[0,0]\n",
    "    l_temp = l[0,0]\n",
    "    data_r.append(r_temp['image'][0][0])\n",
    "    data_r.append(r_temp['gaze'][0][0])\n",
    "    data_r.append(r_temp['pose'][0][0])\n",
    "    data_l.append(l_temp['image'][0][0])\n",
    "    data_l.append(l_temp['gaze'][0][0])\n",
    "    data_l.append(l_temp['pose'][0][0])\n",
    "    for i in range(3):\n",
    "        data_all.append(data_r[i])   #0 -> r_img, 1-> l_img, 2-> r_gaze, 3->l_gaze..\n",
    "        data_all.append(data_l[i])\n",
    "    return data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_extraction(path, screen_path):\n",
    "    txt = pd.read_csv(path, sep = ' ', header= None)\n",
    "    screen = io.loadmat(screen_path)\n",
    "    df_anno = pd.DataFrame(txt)\n",
    "    data_frame = pd.DataFrame()\n",
    "    data_frame['Screen_x'] = df_anno[:][24] / screen['width_pixel'][0][0]\n",
    "    data_frame['Screen_y'] = df_anno[:][25] / screen['height_pixel'][0][0]\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def path_optimization(day_list, path):\n",
    "    all_path = []\n",
    "    cnt = 0\n",
    "    for i in range(len(day_list)): # 15번 \n",
    "        temp = []\n",
    "        for j in range(day_list[i]):\n",
    "            temp.append(path[cnt])\n",
    "            cnt += 1\n",
    "        all_path.append(temp)\n",
    "    return all_path\n",
    "\n",
    "day_list = [39, 69, 39, 65, 25, 38, 62, 56, 47, 20, 16, 19, 7, 12, 7]  \n",
    "data_path = glob('../Data/MPIIGaze/Data/Normalized/*/*') # 521개\n",
    "data_path.sort() #data sorting for labeling\n",
    "data_path = path_optimization(day_list, data_path)\n",
    "#data_path = path_optimization(glob('C:/MPIIGaze/MPIIGaze/Data/Normalized/*/*'))\n",
    "label_path = glob('../Data/MPIIGaze/Data/Original/*/*/annotation.txt') # 521개\n",
    "label_path.sort() #label sorting for labeling\n",
    "label_path = path_optimization(day_list, label_path)\n",
    "#label_path = path_optimzation(glob('C:/MPIIGaze/MPIIGaze/Data/Original/*/*/annotation.txt'))\n",
    "screen_size_path = glob('../Data/MPIIGaze/Data/Original/*/Calibration/screenSize.mat') # 15개\n",
    "\n",
    "for i in range(15): # 총 15명\n",
    "    data = [] # 사람별로 나눈 데이터\n",
    "    label = [] # 사람별로 나눈 라벨   \n",
    "    for j in range(day_list[i]): # 각 사람에 맞는 day만큼\n",
    "        data.append(data_extraction(data_path[i][j]))\n",
    "        label.append(label_extraction(label_path[i][j], screen_size_path[i]))\n",
    "    exec('p%d_data = data' % (i))\n",
    "    exec('p%d_label = label' % (i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_img_label(image_shape, label_shape, data_list, label_list):\n",
    "    length = len(data_list[0])\n",
    "    length_2 = len(label_list[0])\n",
    "    if(length != length_2):\n",
    "        print('Datas and Labels Dimenssion are different')\n",
    "        break\n",
    "    left_img = np.zeros([length,image_shape])\n",
    "    right_img = np.zeros([length,image_shape])\n",
    "    label = np.zeros([length,label_shape])\n",
    "    for n in range(length):\n",
    "        left_img[n, :] = data_list[1][n].reshape(image_shape)\n",
    "        right_img[n, :] = data_list[0][n].reshape(image_shape)\n",
    "        label[n, :] = [label_list['Screen_x'][n], label_list['Screen_y'][n]]\n",
    "        \n",
    "    return right_img, left_img, label\n",
    "\n",
    "def make_dataset_gaze_pose(data_shape, data_list):\n",
    "    length = len(data_list[0])\n",
    "    left_pose = np.zeros([length,data_shape])\n",
    "    right_pose = np.zeros([length,data_shape])\n",
    "    left_gaze = np.zeros([length,data_shape])\n",
    "    right_gaze = np.zeros([length,data_shape])\n",
    "    for n in range(length):\n",
    "        left_gaze[n, :] = data_list[3][n]\n",
    "        right_gaze[n, :] = data_list[2][n]\n",
    "        left_pose[n, :] = data_list[5][n]\n",
    "        right_pose[n, :] = data_list[4][n]\n",
    "    return left_gaze, right_gaze, left_pose, right_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_RE_img_data = []\n",
    "Batch_LE_img_data = []\n",
    "Batch_LE_gaze_data = []\n",
    "Batch_RE_gaze_data = [] \n",
    "Batch_LE_pose_data = []\n",
    "Batch_RE_pose_data = []\n",
    "Batch_label = []\n",
    "for i in range(15):\n",
    "    for j in range(day_list[i]): #days list in Data  po -> 39days  ..\n",
    "        exec('RE_img_data, LE_img_data, dataset_label = make_dataset_img_label(36 * 60, 2, p{0}_data[{1}], p{2}_label[{3}])'.format(i, j, i, j))\n",
    "        exec('LE_gaze_data, RE_gaze_data, LE_pose_data, RE_pose_data = make_dataset_gaze_pose(3, p{0}_data[{1}])'.format(i, j))\n",
    "        Batch_RE_img_data.append(RE_img_data)\n",
    "        Batch_LE_img_data.append(LE_img_data)\n",
    "        Batch_LE_gaze_data.append(LE_gaze_data)\n",
    "        Batch_RE_gaze_data.append(RE_gaze_data)\n",
    "        Batch_LE_pose_data.append(LE_pose_data)\n",
    "        Batch_RE_pose_data.append(RE_pose_data)\n",
    "        Batch_label.append(dataset_label)\n",
    "\n",
    "    #Delete used data\n",
    "    exec('del(p{0}_data)'.format(i))\n",
    "    exec('del(p{0}_label)'.format(i))\n",
    "\n",
    "del(data_path)\n",
    "del(label_path)\n",
    "del(screen_size_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Batch_RE_gaze_data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make graph for eye images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_for_image(X_img, keep_prob, name):\n",
    "    W1 = tf.Variable(tf.random_normal([4, 4, 1, 5], stddev=0.01))\n",
    "    L1 = tf.nn.conv2d(X_img, W1, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    L1 = tf.nn.relu(L1)\n",
    "\n",
    "    print(L1)\n",
    "\n",
    "    W2 = tf.Variable(tf.random_normal([2, 2, 5, 10], stddev=0.01))\n",
    "    L2 = tf.nn.conv2d(L1, W2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    L2 = tf.nn.relu(L2)\n",
    "    L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "    L2_flat = tf.reshape(L2, [-1, 5 * 8 * 10])\n",
    "    \n",
    "    print(\"'L2's shape\",L2.shape)\n",
    "    print(L2_flat)\n",
    "\n",
    "\n",
    "    W3 = tf.get_variable(\"W3_\"+name ,shape= [400, 256],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "    b3 = tf.Variable(tf.random_normal([256]))\n",
    "    L3 = tf.nn.relu(tf.matmul(L2_flat, W3) + b3)\n",
    "    L3 = tf.nn.dropout(L3, keep_prob= keep_prob)\n",
    "\n",
    "    print(L3.shape)\n",
    "\n",
    "    W4 = tf.get_variable(\"W4_\"+name ,shape= [256, 128],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "    b4 = tf.Variable(tf.random_normal([128]))\n",
    "    L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "    L4 = tf.nn.dropout(L4, keep_prob= keep_prob)\n",
    "    \n",
    "    W5 = tf.get_variable(\"W5_\"+name ,shape= [128, 64],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "    b5 = tf.Variable(tf.random_normal([64]))\n",
    "    logits = tf.matmul(L4, W5) + b5\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make graph for other datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_for_others(X, name):\n",
    "    W1 = tf.get_variable(\"W1_\"+name ,shape= [3, 3],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "    b1 = tf.Variable(tf.random_normal([3]))\n",
    "    L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "    print(L1.shape)\n",
    "\n",
    "    W2 = tf.get_variable(\"W2_\"+name ,shape= [3, 3],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "    b2 = tf.Variable(tf.random_normal([3]))\n",
    "    logits = tf.matmul(L1, W2) + b2\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define variable and make graphs using function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "Y = tf.placeholder(tf.float32, [None, 2])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "X_left = tf.placeholder(tf.float32, [None, 2160])\n",
    "X_right = tf.placeholder(tf.float32, [None, 2160])\n",
    "X_img_left = tf.reshape(X_left, [-1, 36, 60, 1])   \n",
    "X_img_right = tf.reshape(X_right, [-1, 36, 60, 1]) \n",
    "\n",
    "X_gaze_r = tf.placeholder(tf.float32, [None, 3])\n",
    "X_gaze_l = tf.placeholder(tf.float32, [None, 3])\n",
    "X_pose_r = tf.placeholder(tf.float32, [None, 3])\n",
    "X_pose_l = tf.placeholder(tf.float32, [None, 3])\n",
    "\n",
    "LE_img = model_for_image(X_img_left, keep_prob, 'left_eye')  #left eye imgae\n",
    "RE_img = model_for_image(X_img_right, keep_prob, 'right_eye')#right eye image\n",
    "LE_pose = model_for_others(X_pose_l, 'left_pose')\n",
    "LE_gaze = model_for_others(X_gaze_l, 'left_gaze')\n",
    "RE_pose = model_for_others(X_pose_r, 'right_pose')\n",
    "RE_gaze = model_for_others(X_gaze_r, 'right_gaze')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate the gaze graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LE_gaze_W = tf.get_variable(\"LE_gaze_W\" ,shape= [3, 3],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "RE_gaze_W = tf.get_variable(\"RE_gaze_W\" ,shape= [3, 3],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "layer_gaze = tf.nn.relu(tf.matmul(LE_gaze, LE_gaze_W) + tf.matmul(RE_gaze, RE_gaze_W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate the pose layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LE_pose_W = tf.get_variable(\"LE_pose_W\" ,shape= [3, 3],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "RE_pose_W = tf.get_variable(\"RE_pose_W\" ,shape= [3, 3],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "layer_pose = tf.nn.relu(tf.matmul(LE_pose, LE_pose_W) + tf.matmul(RE_pose, RE_pose_W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate the Image layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LE_W_img = tf.get_variable(\"LE_W_img\" ,shape= [64, 32],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "RE_W_img = tf.get_variable(\"RE_W_img\" ,shape= [64, 32],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "layer_img = tf.nn.relu(tf.matmul(LE_img, LE_W_img) + tf.matmul(RE_img, RE_W_img))\n",
    "\n",
    "img_W = tf.get_variable(\"img_W\" ,shape= [32, 16],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "img_b = tf.Variable(tf.random_normal([16]))\n",
    "layer2_img = tf.nn.relu(tf.matmul(layer_img, img_W) + img_b)\n",
    "\n",
    "img_W2 = tf.get_variable(\"img_W2\" ,shape= [16, 8],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "img_b2 = tf.Variable(tf.random_normal([8]))\n",
    "layer3_img= tf.nn.relu(tf.matmul(layer2_img, img_W2) + img_b2)\n",
    "\n",
    "Final_W_img = tf.get_variable(\"Final_W_img\" ,shape= [8, 3],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "Final_b_img = tf.Variable(tf.random_normal([3]))\n",
    "Final_layer_img= tf.nn.relu(tf.matmul(layer3_img, Final_W_img) + Final_b_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight and bias for img layer\n",
    "All_W_img = tf.get_variable(\"All_W_img\" ,shape= [3, 2],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "# Weight and bias for pose layer\n",
    "All_W_pose = tf.get_variable(\"All_W_pose\" ,shape= [3, 2],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "# Weight and bias for gaze layer\n",
    "All_W_gaze = tf.get_variable(\"All_W_gaze\" ,shape= [3, 2],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "\n",
    "logits = (tf.matmul(Final_layer_img, All_W_img) \n",
    "          + tf.matmul(layer_pose, All_W_pose)\n",
    "          + tf.matmul(layer_gaze, All_W_gaze))\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(logits-Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning started. It takes sometime.')\n",
    "for i in range(521):\n",
    "    Batch_size = len(Batch_LE_gaze_data)\n",
    "    for j in range(Batch_size):\n",
    "        feed_dict = {X_right: Batch_RE_img_data[i],X_left: Batch_LE_img_data[i],\n",
    "                     X_gaze_r:Batch_RE_gaze_data[i], X_gaze_l:Batch_LE_gaze_data[i],\n",
    "                     X_pose_r:Batch_RE_pose_data[i], X_pose_l:Batch_LE_pose_data[i],\n",
    "                     Y:Batch_label[i], keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "    print('step: {0}, cost: {1}'.format(i, c))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
