{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import matplotlib.cm as cm\n",
    "from scipy.misc import imresize\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import scipy.io as io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction and Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extraction(path):\n",
    "    data_l, data_r, data_all = [], [], []\n",
    "    nor_data = io.loadmat(path)\n",
    "    temp = nor_data['data']\n",
    "    r = temp['right']\n",
    "    l = temp['left']\n",
    "    r_temp = r[0,0]\n",
    "    l_temp = l[0,0]\n",
    "    data_r.append(r_temp['image'][0][0])\n",
    "    data_r.append(r_temp['gaze'][0][0])\n",
    "    data_r.append(r_temp['pose'][0][0])\n",
    "    data_l.append(l_temp['image'][0][0])\n",
    "    data_l.append(l_temp['gaze'][0][0])\n",
    "    data_l.append(l_temp['pose'][0][0])\n",
    "    for i in range(3):\n",
    "        data_all.append(data_r[i])   #0 -> r_img, 1-> l_img, 2-> r_gaze, 3->l_gaze..\n",
    "        data_all.append(data_l[i])\n",
    "    return data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_extraction(path, screen_path):\n",
    "    txt = pd.read_csv(path, sep = ' ', header= None)\n",
    "    screen = io.loadmat(screen_path)\n",
    "    df_anno = pd.DataFrame(txt)\n",
    "    data_frame = pd.DataFrame()\n",
    "    data_frame['Screen_x'] = df_anno[:][24] / screen['width_pixel'][0][0]\n",
    "    data_frame['Screen_y'] = df_anno[:][25] / screen['height_pixel'][0][0]\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def path_optimization(day_list, path):\n",
    "    all_path = []\n",
    "    cnt = 0\n",
    "    for i in range(len(day_list)): # 15번 \n",
    "        temp = []\n",
    "        for j in range(day_list[i]):\n",
    "            temp.append(path[cnt])\n",
    "            cnt += 1\n",
    "        all_path.append(temp)\n",
    "    return all_path\n",
    "\n",
    "day_list = [39, 69, 39, 65, 25, 38, 62, 56, 47, 20, 16, 19, 7, 12, 7]  \n",
    "data_path = glob('../Data/MPIIGaze/Data/Normalized/*/*') # 521개\n",
    "data_path.sort() #data sorting for labeling\n",
    "data_path = path_optimization(day_list, data_path)\n",
    "#data_path = path_optimization(glob('C:/MPIIGaze/MPIIGaze/Data/Normalized/*/*'))\n",
    "label_path = glob('../Data/MPIIGaze/Data/Original/*/*/annotation.txt') # 521개\n",
    "label_path.sort() #label sorting for labeling\n",
    "label_path = path_optimization(day_list, label_path)\n",
    "#label_path = path_optimzation(glob('C:/MPIIGaze/MPIIGaze/Data/Original/*/*/annotation.txt'))\n",
    "screen_size_path = glob('../Data/MPIIGaze/Data/Original/*/Calibration/screenSize.mat') # 15개\n",
    "\n",
    "for i in range(15): # 총 15명\n",
    "    data = [] # 사람별로 나눈 데이터\n",
    "    label = [] # 사람별로 나눈 라벨   \n",
    "    for j in range(day_list[i]): # 각 사람에 맞는 day만큼\n",
    "        data.append(data_extraction(data_path[i][j]))\n",
    "        label.append(label_extraction(label_path[i][j], screen_size_path[i]))\n",
    "    exec('p%d_data = data' % (i))\n",
    "    exec('p%d_label = label' % (i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_img_label(image_shape, label_shape, data_list, label_list):\n",
    "    length = len(data_list[0])\n",
    "    length_2 = len(label_list[0])\n",
    "    if(length != length_2):\n",
    "        print('Datas and Labels Dimenssion are different')\n",
    "        break\n",
    "    left_img = np.zeros([length,image_shape])\n",
    "    right_img = np.zeros([length,image_shape])\n",
    "    label = np.zeros([length,label_shape])\n",
    "    for n in range(length):\n",
    "        left_img[n, :] = data_list[1][n].reshape(image_shape)\n",
    "        right_img[n, :] = data_list[0][n].reshape(image_shape)\n",
    "        label[n, :] = [label_list['Screen_x'][n], label_list['Screen_y'][n]]\n",
    "        \n",
    "    return right_img, left_img, label\n",
    "\n",
    "def make_dataset_gaze_pose(data_shape, data_list):\n",
    "    length = len(data_list[0])\n",
    "    left_pose = np.zeros([length,data_shape])\n",
    "    right_pose = np.zeros([length,data_shape])\n",
    "    left_gaze = np.zeros([length,data_shape])\n",
    "    right_gaze = np.zeros([length,data_shape])\n",
    "    for n in range(length):\n",
    "        left_gaze[n, :] = data_list[3][n]\n",
    "        right_gaze[n, :] = data_list[2][n]\n",
    "        left_pose[n, :] = data_list[5][n]\n",
    "        right_pose[n, :] = data_list[4][n]\n",
    "    return left_gaze, right_gaze, left_pose, right_pose"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 8,
>>>>>>> bad72e2b1ba49e7bc7ffd0f5d97d212fd9b4df62
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_RE_img_data = []\n",
    "Batch_LE_img_data = []\n",
    "Batch_LE_gaze_data = []\n",
    "Batch_RE_gaze_data = [] \n",
    "Batch_LE_pose_data = []\n",
    "Batch_RE_pose_data = []\n",
    "Batch_label = []\n",
    "for i in range(15):\n",
    "    for j in range(day_list[i]): #days list in Data  po -> 39days  ..\n",
    "        exec('RE_img_data, LE_img_data, dataset_label = make_dataset_img_label(36 * 60, 2, p{0}_data[{1}], p{2}_label[{3}])'.format(i, j, i, j))\n",
    "        exec('LE_gaze_data, RE_gaze_data, LE_pose_data, RE_pose_data = make_dataset_gaze_pose(3, p{0}_data[{1}])'.format(i, j))\n",
    "        Batch_RE_img_data.append(RE_img_data)\n",
    "        Batch_LE_img_data.append(LE_img_data)\n",
    "        Batch_LE_gaze_data.append(LE_gaze_data)\n",
    "        Batch_RE_gaze_data.append(RE_gaze_data)\n",
    "        Batch_LE_pose_data.append(LE_pose_data)\n",
    "        Batch_RE_pose_data.append(RE_pose_data)\n",
    "        Batch_label.append(dataset_label)\n",
    "\n",
<<<<<<< HEAD
=======
    "    #Delete used data\n",
>>>>>>> bad72e2b1ba49e7bc7ffd0f5d97d212fd9b4df62
    "    exec('del(p{0}_data)'.format(i))\n",
    "    exec('del(p{0}_label)'.format(i))\n",
    "\n",
    "del(data_path)\n",
    "del(label_path)\n",
    "del(screen_size_path)"
<<<<<<< HEAD
=======
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Batch_RE_gaze_data[0].shape"
>>>>>>> bad72e2b1ba49e7bc7ffd0f5d97d212fd9b4df62
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make graph for eye images"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": null,
>>>>>>> bad72e2b1ba49e7bc7ffd0f5d97d212fd9b4df62
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_for_image(X_img, keep_prob, name):\n",
    "    W1 = tf.Variable(tf.random_normal([4, 4, 1, 5], stddev=0.01))\n",
    "    L1 = tf.nn.conv2d(X_img, W1, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    L1 = tf.nn.relu(L1)\n",
    "\n",
    "    print(L1)\n",
    "\n",
    "    W2 = tf.Variable(tf.random_normal([2, 2, 5, 10], stddev=0.01))\n",
    "    L2 = tf.nn.conv2d(L1, W2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    L2 = tf.nn.relu(L2)\n",
    "    L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "    L2_flat = tf.reshape(L2, [-1, 5 * 8 * 10])\n",
    "    \n",
    "    print(\"'L2's shape\",L2.shape)\n",
    "    print(L2_flat)\n",
    "\n",
    "\n",
    "    W3 = tf.get_variable(\"W3_\"+name ,shape= [400, 256],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "    b3 = tf.Variable(tf.random_normal([256]))\n",
    "    L3 = tf.nn.relu(tf.matmul(L2_flat, W3) + b3)\n",
    "    L3 = tf.nn.dropout(L3, keep_prob= keep_prob)\n",
    "\n",
    "    print(L3.shape)\n",
    "\n",
    "    W4 = tf.get_variable(\"W4_\"+name ,shape= [256, 128],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "    b4 = tf.Variable(tf.random_normal([128]))\n",
    "    L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "    L4 = tf.nn.dropout(L4, keep_prob= keep_prob)\n",
    "    \n",
    "    W5 = tf.get_variable(\"W5_\"+name ,shape= [128, 64],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "    b5 = tf.Variable(tf.random_normal([64]))\n",
    "    logits = tf.matmul(L4, W5) + b5\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make graph for other datas"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": null,
>>>>>>> bad72e2b1ba49e7bc7ffd0f5d97d212fd9b4df62
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_for_others(X, name):\n",
    "    W1 = tf.get_variable(\"W1_\"+name ,shape= [3, 3],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "    b1 = tf.Variable(tf.random_normal([3]))\n",
    "    L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "    print(L1.shape)\n",
    "\n",
    "    W2 = tf.get_variable(\"W2_\"+name ,shape= [3, 3],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "    b2 = tf.Variable(tf.random_normal([3]))\n",
    "    logits = tf.matmul(L1, W2) + b2\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define variable and make graphs using function"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/spow12/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Tensor(\"Relu:0\", shape=(?, 18, 30, 5), dtype=float32)\n",
      "'L2's shape (?, 5, 8, 10)\n",
      "Tensor(\"Reshape_2:0\", shape=(?, 400), dtype=float32)\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-7-0c7719e4292b>:23: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "(?, 256)\n",
      "Tensor(\"Relu_4:0\", shape=(?, 18, 30, 5), dtype=float32)\n",
      "'L2's shape (?, 5, 8, 10)\n",
      "Tensor(\"Reshape_3:0\", shape=(?, 400), dtype=float32)\n",
      "(?, 256)\n",
      "(?, 3)\n",
      "(?, 3)\n",
      "(?, 3)\n",
      "(?, 3)\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
>>>>>>> bad72e2b1ba49e7bc7ffd0f5d97d212fd9b4df62
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "Y = tf.placeholder(tf.float32, [None, 2])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "X_left = tf.placeholder(tf.float32, [None, 2160])\n",
    "X_right = tf.placeholder(tf.float32, [None, 2160])\n",
    "X_img_left = tf.reshape(X_left, [-1, 36, 60, 1])   \n",
    "X_img_right = tf.reshape(X_right, [-1, 36, 60, 1]) \n",
    "\n",
    "X_gaze_r = tf.placeholder(tf.float32, [None, 3])\n",
    "X_gaze_l = tf.placeholder(tf.float32, [None, 3])\n",
    "X_pose_r = tf.placeholder(tf.float32, [None, 3])\n",
    "X_pose_l = tf.placeholder(tf.float32, [None, 3])\n",
    "\n",
    "LE_img = model_for_image(X_img_left, keep_prob, 'left_eye')  #left eye imgae\n",
    "RE_img = model_for_image(X_img_right, keep_prob, 'right_eye')#right eye image\n",
    "LE_pose = model_for_others(X_pose_l, 'left_pose')\n",
    "LE_gaze = model_for_others(X_gaze_l, 'left_gaze')\n",
    "RE_pose = model_for_others(X_pose_r, 'right_pose')\n",
    "RE_gaze = model_for_others(X_gaze_r, 'right_gaze')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate the gaze graph"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": null,
>>>>>>> bad72e2b1ba49e7bc7ffd0f5d97d212fd9b4df62
   "metadata": {},
   "outputs": [],
   "source": [
    "LE_gaze_W = tf.get_variable(\"LE_gaze_W\" ,shape= [3, 3],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "RE_gaze_W = tf.get_variable(\"RE_gaze_W\" ,shape= [3, 3],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "layer_gaze = tf.nn.relu(tf.matmul(LE_gaze, LE_gaze_W) + tf.matmul(RE_gaze, RE_gaze_W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate the pose layer"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": null,
>>>>>>> bad72e2b1ba49e7bc7ffd0f5d97d212fd9b4df62
   "metadata": {},
   "outputs": [],
   "source": [
    "LE_pose_W = tf.get_variable(\"LE_pose_W\" ,shape= [3, 3],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "RE_pose_W = tf.get_variable(\"RE_pose_W\" ,shape= [3, 3],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "layer_pose = tf.nn.relu(tf.matmul(LE_pose, LE_pose_W) + tf.matmul(RE_pose, RE_pose_W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate the Image layer"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": null,
>>>>>>> bad72e2b1ba49e7bc7ffd0f5d97d212fd9b4df62
   "metadata": {},
   "outputs": [],
   "source": [
    "LE_W_img = tf.get_variable(\"LE_W_img\" ,shape= [64, 32],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "RE_W_img = tf.get_variable(\"RE_W_img\" ,shape= [64, 32],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "layer_img = tf.nn.relu(tf.matmul(LE_img, LE_W_img) + tf.matmul(RE_img, RE_W_img))\n",
    "\n",
    "img_W = tf.get_variable(\"img_W\" ,shape= [32, 16],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "img_b = tf.Variable(tf.random_normal([16]))\n",
    "layer2_img = tf.nn.relu(tf.matmul(layer_img, img_W) + img_b)\n",
    "\n",
    "img_W2 = tf.get_variable(\"img_W2\" ,shape= [16, 8],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "img_b2 = tf.Variable(tf.random_normal([8]))\n",
    "layer3_img= tf.nn.relu(tf.matmul(layer2_img, img_W2) + img_b2)\n",
    "\n",
    "Final_W_img = tf.get_variable(\"Final_W_img\" ,shape= [8, 3],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "Final_b_img = tf.Variable(tf.random_normal([3]))\n",
    "Final_layer_img= tf.nn.relu(tf.matmul(layer3_img, Final_W_img) + Final_b_img)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": null,
>>>>>>> bad72e2b1ba49e7bc7ffd0f5d97d212fd9b4df62
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight and bias for img layer\n",
    "All_W_img = tf.get_variable(\"All_W_img\" ,shape= [3, 2],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "# Weight and bias for pose layer\n",
    "All_W_pose = tf.get_variable(\"All_W_pose\" ,shape= [3, 2],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "# Weight and bias for gaze layer\n",
    "All_W_gaze = tf.get_variable(\"All_W_gaze\" ,shape= [3, 2],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "\n",
    "logits = (tf.matmul(Final_layer_img, All_W_img) \n",
    "          + tf.matmul(layer_pose, All_W_pose)\n",
    "          + tf.matmul(layer_gaze, All_W_gaze))\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(logits-Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "step: 0, cost: 0.007475428283214569\n",
      "step: 5, cost: 0.0014524610014632344\n",
      "step: 10, cost: 0.00020366378885228187\n",
      "step: 15, cost: 0.00021137908333912492\n",
      "step: 20, cost: 0.00011583992454688996\n",
      "step: 25, cost: 0.00010098019993165508\n",
      "step: 30, cost: 0.00013419712195172906\n",
      "step: 35, cost: 9.956023131962866e-05\n",
      "step: 40, cost: 0.00012206359679112211\n",
      "step: 45, cost: 0.00010790628584800288\n",
      "step: 50, cost: 5.258014061837457e-05\n",
      "step: 55, cost: 4.9087182560469955e-05\n",
      "step: 60, cost: 4.591557808453217e-05\n",
      "step: 65, cost: 5.658406007569283e-05\n",
      "step: 70, cost: 4.764521145261824e-05\n",
      "step: 75, cost: 6.72240203130059e-05\n",
      "step: 80, cost: 0.00011267178342677653\n",
      "step: 85, cost: 0.0001209556867252104\n",
      "step: 90, cost: 8.323907968588173e-05\n",
      "step: 95, cost: 7.981791713973507e-05\n",
      "step: 100, cost: 0.0001126155475503765\n",
      "step: 105, cost: 0.0001285208563786\n",
      "step: 110, cost: 0.00018792666378431022\n",
      "step: 115, cost: 0.00021544996707234532\n",
      "step: 120, cost: 0.00031449622474610806\n",
      "step: 125, cost: 0.00021690339781343937\n",
      "step: 130, cost: 0.00035230338107794523\n",
      "step: 135, cost: 8.574590901844203e-05\n",
      "step: 140, cost: 0.00017001085507217795\n",
      "step: 145, cost: 7.39240858820267e-05\n",
      "step: 150, cost: 5.188702925806865e-05\n",
      "step: 155, cost: 4.875047306995839e-05\n",
      "step: 160, cost: 6.233818567125127e-05\n",
      "step: 165, cost: 0.0001417948806192726\n",
      "step: 170, cost: 8.19508932181634e-05\n",
      "step: 175, cost: 0.0002352024894207716\n",
      "step: 180, cost: 0.00010192671470576897\n",
      "step: 185, cost: 0.0002903534041251987\n",
      "step: 190, cost: 0.0003119026077911258\n",
      "step: 195, cost: 0.00030933591187931597\n",
      "step: 200, cost: 0.0003014509566128254\n",
      "step: 205, cost: 0.00025362055748701096\n",
      "step: 210, cost: 0.00024856533855199814\n",
      "step: 215, cost: 0.00017848772404249758\n",
      "step: 220, cost: 0.0001587422884767875\n",
      "step: 225, cost: 0.00012509796943049878\n",
      "step: 230, cost: 0.00014377622574102134\n",
      "step: 235, cost: 0.0001226557360496372\n",
      "step: 240, cost: 0.0002033742202911526\n",
      "step: 245, cost: 0.0002734137524385005\n",
      "step: 250, cost: 0.00045381675590761006\n",
      "step: 255, cost: 0.0004832353733945638\n",
      "step: 260, cost: 0.000200504859094508\n",
      "step: 265, cost: 0.00021396568627096713\n",
      "step: 270, cost: 0.00016191345639526844\n",
      "step: 275, cost: 0.0011937364470213652\n",
      "step: 280, cost: 0.002235300140455365\n",
      "step: 285, cost: 0.0011101572308689356\n",
      "step: 290, cost: 0.0008866668795235455\n",
      "step: 295, cost: 0.0006083904881961644\n",
      "step: 300, cost: 0.0014601597795262933\n",
      "step: 305, cost: 0.000991846900433302\n",
      "step: 310, cost: 0.0009328850428573787\n",
      "step: 315, cost: 0.000536954088602215\n",
      "step: 320, cost: 0.0005326641257852316\n",
      "step: 325, cost: 0.0011729958932846785\n",
      "step: 330, cost: 0.0011259664315730333\n",
      "step: 335, cost: 0.0012370676267892122\n",
      "step: 340, cost: 0.00027468946063891053\n",
      "step: 345, cost: 0.0001689874625299126\n",
      "step: 350, cost: 0.00020939415844623\n",
      "step: 355, cost: 0.0006075671990402043\n",
      "step: 360, cost: 0.0004353381518740207\n",
      "step: 365, cost: 0.00039447261951863766\n",
      "step: 370, cost: 0.00021125542116351426\n",
      "step: 375, cost: 0.00022514746524393559\n",
      "step: 380, cost: 0.00032232646481134\n",
      "step: 385, cost: 0.0003456351696513593\n",
      "step: 390, cost: 0.0003922560717910528\n",
      "step: 395, cost: 9.507938375463709e-05\n",
      "step: 400, cost: 8.134639938361943e-05\n",
      "step: 405, cost: 0.0006430550129152834\n",
      "step: 410, cost: 0.0017275451682507992\n",
      "step: 415, cost: 0.0003567591484170407\n",
      "step: 420, cost: 0.0004701893776655197\n",
      "step: 425, cost: 0.0010216287337243557\n",
      "step: 430, cost: 0.002377032535150647\n",
      "step: 435, cost: 0.0009518256993032992\n",
      "step: 440, cost: 0.0004172037879470736\n",
      "step: 445, cost: 0.0008624690235592425\n",
      "step: 450, cost: 0.0003105454088654369\n",
      "step: 455, cost: 8.684992280905135e-06\n",
      "step: 460, cost: 0.0001173048876808025\n",
      "step: 465, cost: 0.00017260460299439728\n",
      "step: 470, cost: 0.0002176616690121591\n",
      "step: 475, cost: 0.00014654992264695466\n",
      "step: 480, cost: 8.372651791432872e-05\n",
      "step: 485, cost: 0.0003857355914078653\n",
      "step: 490, cost: 0.0002823800314217806\n",
      "step: 495, cost: 0.0003574869188014418\n",
      "step: 500, cost: 0.00019035337027162313\n",
      "step: 505, cost: 0.0004147834551986307\n",
      "step: 510, cost: 0.00014634460967499763\n",
      "step: 515, cost: 0.0005716995801776648\n",
      "step: 520, cost: 0.0005800498183816671\n",
      "step: 520, cost: 0.0005800498183816671\n",
      "\n",
      "Learning Finished!\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> bad72e2b1ba49e7bc7ffd0f5d97d212fd9b4df62
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning started. It takes sometime.')\n",
    "for i in range(521):\n",
    "    Batch_size = len(Batch_LE_gaze_data)\n",
    "    for j in range(Batch_size):\n",
    "        feed_dict = {X_right: Batch_RE_img_data[i],X_left: Batch_LE_img_data[i],\n",
    "                     X_gaze_r:Batch_RE_gaze_data[i], X_gaze_l:Batch_LE_gaze_data[i],\n",
    "                     X_pose_r:Batch_RE_pose_data[i], X_pose_l:Batch_LE_pose_data[i],\n",
    "                     Y:Batch_label[i], keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "    if i % 5 == 0:\n",
    "        print('step: {0}, cost: {1}'.format(i, c))\n",
    "\n",
    "print('step: {0}, cost: {1}\\n'.format(i, c))\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
