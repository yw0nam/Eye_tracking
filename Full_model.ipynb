{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import matplotlib.cm as cm\n",
    "from scipy.misc import imresize\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import scipy.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extraction(path):\n",
    "    data_l, data_r, data_all = [], [], []\n",
    "    nor_data = io.loadmat(path)\n",
    "    temp = nor_data['data']\n",
    "    r = temp['right']\n",
    "    l = temp['left']\n",
    "    r_temp = r[0,0]\n",
    "    l_temp = l[0,0]\n",
    "    data_r.append(r_temp['image'][0][0])\n",
    "    data_r.append(r_temp['gaze'][0][0])\n",
    "    data_r.append(r_temp['pose'][0][0])\n",
    "    data_l.append(l_temp['image'][0][0])\n",
    "    data_l.append(l_temp['gaze'][0][0])\n",
    "    data_l.append(l_temp['pose'][0][0])\n",
    "    for i in range(3):\n",
    "        data_all.append(data_r[i])   #0 -> r_img, 1-> l_img, 2-> r_gaze, 3->l_gaze..\n",
    "        data_all.append(data_l[i])\n",
    "    return data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_extraction(path, screen_path):\n",
    "    txt = pd.read_csv(path, sep = ' ', header= None)\n",
    "    screen = io.loadmat(screen_path)\n",
    "    df_anno = pd.DataFrame(txt)\n",
    "    data_frame = pd.DataFrame()\n",
    "    data_frame['Screen_x'] = df_anno[:][24] / screen['width_pixel'][0][0]\n",
    "    data_frame['Screen_y'] = df_anno[:][25] / screen['height_pixel'][0][0]\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def path_optimization(day_list, path):\n",
    "    all_path = []\n",
    "    cnt = 0\n",
    "    for i in range(len(day_list)): # 15번 \n",
    "        temp = []\n",
    "        for j in range(day_list[i]):\n",
    "            temp.append(path[cnt])\n",
    "            cnt += 1\n",
    "        all_path.append(temp)\n",
    "    return all_path\n",
    "\n",
    "day_list = [39, 69, 39, 65, 25, 38, 62, 56, 47, 20, 16, 19, 7, 12, 7]  \n",
    "data_path = glob('../Data/MPIIGaze/Data/Normalized/*/*')# 521개\n",
    "data_path.sort()    #Sort for prevent index error\n",
    "data_path = path_optimization(day_list, data_path)\n",
    "#data_path = path_optimization(glob('C:/MPIIGaze/MPIIGaze/Data/Normalized/*/*'))\n",
    "label_path = glob('../Data/MPIIGaze/Data//Original/*/*/annotation.txt') # 521개\n",
    "label_path.sort()\n",
    "label_path = path_optimization(day_list, label_path)\n",
    "#label_path = path_optimzation(glob('C:/MPIIGaze/MPIIGaze/Data/Original/*/*/annotation.txt'))\n",
    "screen_size_path = glob('../Data/MPIIGaze/Data/Original/*/Calibration/screenSize.mat') # 15개\n",
    "\n",
    "for i in range(15): # 총 15명\n",
    "    data = [] # 사람별로 나눈 데이터\n",
    "    label = [] # 사람별로 나눈 라벨   \n",
    "    for j in range(day_list[i]): # 각 사람에 맞는 day만큼\n",
    "        data.append(data_extraction(data_path[i][j]))\n",
    "        label.append(label_extraction(label_path[i][j], screen_size_path[i]))\n",
    "    exec('p%d_data = data' % (i))\n",
    "    exec('p%d_label = label' % (i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_img_label(image_shape, label_shape, data_list, label_list):\n",
    "    length = len(data_list[0])\n",
    "    left_img = np.zeros([length,image_shape])\n",
    "    right_img = np.zeros([length,image_shape])\n",
    "    label = np.zeros([length,label_shape])\n",
    "    for n in range(length):\n",
    "        left_img[n, :] = data_list[1][n].reshape(image_shape)\n",
    "        right_img[n, :] = data_list[0][n].reshape(image_shape)\n",
    "        label[n, :] = [label_list['Screen_x'][n], label_list['Screen_y'][n]]\n",
    "        \n",
    "    return right_img, left_img, label\n",
    "\n",
    "def make_dataset_gaze_pose(data_shape, data_list):\n",
    "    length = len(data_list[0])\n",
    "    left_pose = np.zeros([length,data_shape])\n",
    "    right_pose = np.zeros([length,data_shape])\n",
    "    left_gaze = np.zeros([length,data_shape])\n",
    "    right_gaze = np.zeros([length,data_shape])\n",
    "    for n in range(length):\n",
    "        left_gaze[n, :] = data_list[3][n]\n",
    "        right_gaze[n, :] = data_list[2][n]\n",
    "        left_pose[n, :] = data_list[5][n]\n",
    "        right_pose[n, :] = data_list[4][n]\n",
    "    return left_gaze, right_gaze, left_pose, right_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_RE_img_data = []\n",
    "Batch_LE_img_data = []\n",
    "Batch_LE_gaze_data = []\n",
    "Batch_RE_gaze_data = [] \n",
    "Batch_LE_pose_data = []\n",
    "Batch_RE_pose_data = []\n",
    "Batch_label = []\n",
    "for i in range(15):\n",
    "    for j in range(day_list[i]): #days list in Data  po -> 39days  ..\n",
    "        exec('RE_img_data, LE_img_data, dataset_label = make_dataset_img_label(36 * 60, 2, p{0}_data[{1}], p{2}_label[{3}])'\n",
    "             .format(i, j, i, j))\n",
    "        exec('LE_gaze_data, RE_gaze_data, LE_pose_data, RE_pose_data = make_dataset_gaze_pose(3, p{0}_data[{1}])'.format(i, j))\n",
    "        Batch_RE_img_data.append(RE_img_data)\n",
    "        Batch_LE_img_data.append(LE_img_data)\n",
    "        Batch_LE_gaze_data.append(LE_gaze_data)\n",
    "        Batch_RE_gaze_data.append(RE_gaze_data)\n",
    "        Batch_LE_pose_data.append(LE_pose_data)\n",
    "        Batch_RE_pose_data.append(RE_pose_data)\n",
    "        Batch_label.append(dataset_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make graph for eye images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_for_image(X_img, keep_prob, name):\n",
    "    with tf.name_scope(\"Image_layer_1\" + name) as scope:\n",
    "        W1 = tf.Variable(tf.random_normal([4, 4, 1, 5], stddev=0.01))\n",
    "        L1 = tf.nn.conv2d(X_img, W1, strides=[1, 2, 2, 1], padding='SAME')\n",
    "        L1 = tf.nn.relu(L1)\n",
    "\n",
    "    with tf.name_scope(\"Image_layer_2\" + name) as scope:\n",
    "        W2 = tf.Variable(tf.random_normal([2, 2, 5, 10], stddev=0.01))\n",
    "        L2 = tf.nn.conv2d(L1, W2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "        L2 = tf.nn.relu(L2)\n",
    "        L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                            strides=[1, 2, 2, 1], padding='SAME')\n",
    "        L2_flat = tf.reshape(L2, [-1, 5 * 8 * 10])\n",
    "    \n",
    "\n",
    "    with tf.name_scope(\"Image_layer_3\" + name) as scope:\n",
    "        W3 = tf.get_variable(\"W3_\"+name ,shape= [400, 256],\n",
    "                             initializer= tf.contrib.layers.xavier_initializer())\n",
    "        b3 = tf.Variable(tf.random_normal([256]))\n",
    "        L3 = tf.nn.relu(tf.matmul(L2_flat, W3) + b3)\n",
    "        L3 = tf.nn.dropout(L3, keep_prob= keep_prob)\n",
    "\n",
    "    with tf.name_scope(\"Image_layer_4\" + name) as scope:\n",
    "        W4 = tf.get_variable(\"W4_\"+name ,shape= [256, 128],\n",
    "                             initializer= tf.contrib.layers.xavier_initializer())\n",
    "        b4 = tf.Variable(tf.random_normal([128]))\n",
    "        L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "        L4 = tf.nn.dropout(L4, keep_prob= keep_prob)\n",
    "    \n",
    "    with tf.name_scope(\"Image_layer_5\" + name) as scope:\n",
    "        W5 = tf.get_variable(\"W5_\"+name ,shape= [128, 64],\n",
    "                             initializer= tf.contrib.layers.xavier_initializer())\n",
    "        b5 = tf.Variable(tf.random_normal([64]))\n",
    "        logits = tf.matmul(L4, W5) + b5\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make graph for other datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_for_others(X, name):\n",
    "    with tf.name_scope(\"Layer_1\" + name) as scope:\n",
    "        W1 = tf.get_variable(\"W1_\"+name ,shape= [3, 3],\n",
    "                             initializer= tf.contrib.layers.xavier_initializer())\n",
    "        b1 = tf.Variable(tf.random_normal([3]))\n",
    "        L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "    with tf.name_scope(\"Layer_2\" + name) as scope:\n",
    "        W2 = tf.get_variable(\"W2_\"+name ,shape= [3, 3],\n",
    "                             initializer= tf.contrib.layers.xavier_initializer())\n",
    "        b2 = tf.Variable(tf.random_normal([3]))\n",
    "        logits = tf.matmul(L1, W2) + b2\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define variable and make graphs using function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0708 13:22:46.348640 139829383046912 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0708 13:22:46.358702 139829383046912 deprecation.py:506] From <ipython-input-7-dc5994c33a26>:21: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "Y = tf.placeholder(tf.float32, [None, 2])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "X_left = tf.placeholder(tf.float32, [None, 2160])\n",
    "X_right = tf.placeholder(tf.float32, [None, 2160])\n",
    "X_img_left = tf.reshape(X_left, [-1, 36, 60, 1])   \n",
    "X_img_right = tf.reshape(X_right, [-1, 36, 60, 1]) \n",
    "\n",
    "X_gaze_r = tf.placeholder(tf.float32, [None, 3])\n",
    "X_gaze_l = tf.placeholder(tf.float32, [None, 3])\n",
    "X_pose_r = tf.placeholder(tf.float32, [None, 3])\n",
    "X_pose_l = tf.placeholder(tf.float32, [None, 3])\n",
    "\n",
    "LE_img = model_for_image(X_img_left, keep_prob, 'left_eye')  #left eye imgae\n",
    "RE_img = model_for_image(X_img_right, keep_prob, 'right_eye')#right eye image\n",
    "LE_pose = model_for_others(X_pose_l, 'left_pose')\n",
    "LE_gaze = model_for_others(X_gaze_l, 'left_gaze')\n",
    "RE_pose = model_for_others(X_pose_r, 'right_pose')\n",
    "RE_gaze = model_for_others(X_gaze_r, 'right_gaze')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate the gaze graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Layer_gaze_merged\") as scope:\n",
    "    LE_gaze_W = tf.get_variable(\"LE_gaze_W\" ,shape= [3, 3],\n",
    "                             initializer= tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    RE_gaze_W = tf.get_variable(\"RE_gaze_W\" ,shape= [3, 3],\n",
    "                             initializer= tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    layer_gaze = tf.nn.relu(tf.matmul(LE_gaze, LE_gaze_W) + tf.matmul(RE_gaze, RE_gaze_W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate the pose layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Layer_pose_merged\") as scope:\n",
    "    LE_pose_W = tf.get_variable(\"LE_pose_W\" ,shape= [3, 3],\n",
    "                             initializer= tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    RE_pose_W = tf.get_variable(\"RE_pose_W\" ,shape= [3, 3],\n",
    "                             initializer= tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    layer_pose = tf.nn.relu(tf.matmul(LE_pose, LE_pose_W) + tf.matmul(RE_pose, RE_pose_W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate the Image layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Layer_Image_merged_1\") as scope:\n",
    "    LE_W_img = tf.get_variable(\"LE_W_img\" ,shape= [64, 32],\n",
    "                             initializer= tf.contrib.layers.xavier_initializer())\n",
    "    RE_W_img = tf.get_variable(\"RE_W_img\" ,shape= [64, 32],\n",
    "                             initializer= tf.contrib.layers.xavier_initializer())\n",
    "    layer_img = tf.nn.relu(tf.matmul(LE_img, LE_W_img) + tf.matmul(RE_img, RE_W_img))\n",
    "\n",
    "with tf.name_scope(\"Layer_Image_merged_2\") as scope:\n",
    "    img_W = tf.get_variable(\"img_W\" ,shape= [32, 16],\n",
    "                             initializer= tf.contrib.layers.xavier_initializer())\n",
    "    img_b = tf.Variable(tf.random_normal([16]))\n",
    "    layer2_img = tf.nn.relu(tf.matmul(layer_img, img_W) + img_b)\n",
    "\n",
    "with tf.name_scope(\"Layer_Image_merged_3\") as scope:\n",
    "    img_W2 = tf.get_variable(\"img_W2\" ,shape= [16, 8],\n",
    "                             initializer= tf.contrib.layers.xavier_initializer())\n",
    "    img_b2 = tf.Variable(tf.random_normal([8]))\n",
    "    layer3_img= tf.nn.relu(tf.matmul(layer2_img, img_W2) + img_b2)\n",
    "\n",
    "with tf.name_scope(\"Layer_Image_merged_Last\") as scope:\n",
    "    Final_W_img = tf.get_variable(\"Final_W_img\" ,shape= [8, 3],\n",
    "                             initializer= tf.contrib.layers.xavier_initializer())\n",
    "    Final_b_img = tf.Variable(tf.random_normal([3]))\n",
    "    Final_layer_img= tf.nn.relu(tf.matmul(layer3_img, Final_W_img) + Final_b_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Layer\") as scope:\n",
    "    # Weight and bias for img layer\n",
    "    All_W_img = tf.get_variable(\"All_W_img\" ,shape= [3, 2],\n",
    "                             initializer= tf.contrib.layers.xavier_initializer())\n",
    "    # Weight and bias for pose layer\n",
    "    All_W_pose = tf.get_variable(\"All_W_pose\" ,shape= [3, 2],\n",
    "                             initializer= tf.contrib.layers.xavier_initializer())\n",
    "    # Weight and bias for gaze layer\n",
    "    All_W_gaze = tf.get_variable(\"All_W_gaze\" ,shape= [3, 2],\n",
    "                             initializer= tf.contrib.layers.xavier_initializer())\n",
    "    logits = (tf.matmul(Final_layer_img, All_W_img) \n",
    "              + tf.matmul(layer_pose, All_W_pose)\n",
    "              + tf.matmul(layer_gaze, All_W_gaze))\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(logits-Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "for var in tf.trainable_variables():\n",
    "    tf.summary.histogram(var.op.name, var)\n",
    "\n",
    "summary = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started.\n",
      "step: 0, cost: 0.10700420290231705\n",
      "step: 1, cost: 0.050674792379140854\n",
      "step: 2, cost: 0.03819684311747551\n",
      "step: 3, cost: 0.02675573341548443\n",
      "step: 4, cost: 0.018699513748288155\n",
      "step: 5, cost: 0.011822808533906937\n",
      "step: 6, cost: 0.006867875345051289\n",
      "step: 7, cost: 0.006122950930148363\n",
      "step: 8, cost: 0.005665804725140333\n",
      "step: 9, cost: 0.004236729349941015\n",
      "step: 10, cost: 0.0031538247130811214\n",
      "step: 11, cost: 0.0025854536797851324\n",
      "step: 12, cost: 0.0032718521542847157\n",
      "step: 13, cost: 0.002420193748548627\n",
      "step: 14, cost: 0.0021717865020036697\n",
      "step: 15, cost: 0.003035217057913542\n",
      "step: 16, cost: 0.002703367732465267\n",
      "step: 17, cost: 0.0020157103426754475\n",
      "step: 18, cost: 0.0014856894267722964\n",
      "step: 19, cost: 0.001265054102987051\n",
      "step: 20, cost: 0.001598868751898408\n",
      "step: 21, cost: 0.0016422559274360538\n",
      "step: 22, cost: 0.0024229595437645912\n",
      "step: 23, cost: 0.0019189672311767936\n",
      "step: 24, cost: 0.001286758459173143\n",
      "step: 25, cost: 0.0013555185869336128\n",
      "step: 26, cost: 0.0008879280649125576\n",
      "step: 27, cost: 0.00105986837297678\n",
      "step: 28, cost: 0.0009692757739685476\n",
      "step: 29, cost: 0.001208254136145115\n",
      "step: 30, cost: 0.0008515008958056569\n",
      "step: 31, cost: 0.0009981474140658975\n",
      "step: 32, cost: 0.0011926819570362568\n",
      "step: 33, cost: 0.0006618929328396916\n",
      "step: 34, cost: 0.00078846380347386\n",
      "step: 35, cost: 0.000756026478484273\n",
      "step: 36, cost: 0.0007551357848569751\n",
      "step: 37, cost: 0.000989431282505393\n",
      "step: 38, cost: 0.0005329165142029524\n",
      "step: 39, cost: 0.0012588186655193567\n",
      "step: 40, cost: 0.000748894177377224\n",
      "step: 41, cost: 0.0008855663472786546\n",
      "step: 42, cost: 0.0010095506440848112\n",
      "step: 43, cost: 0.00035168902832083404\n",
      "step: 44, cost: 0.000987813575193286\n",
      "step: 45, cost: 0.0006794998771511018\n",
      "step: 46, cost: 0.0004297904088161886\n",
      "step: 47, cost: 0.00038696109550073743\n",
      "step: 48, cost: 0.0004912400036118925\n",
      "step: 49, cost: 0.0006235685432329774\n",
      "step: 50, cost: 0.0009084964403882623\n",
      "step: 51, cost: 0.00046579877380281687\n",
      "step: 52, cost: 0.0007818519370630383\n",
      "step: 53, cost: 0.00110916537232697\n",
      "step: 54, cost: 0.0006416577380150557\n",
      "step: 55, cost: 0.0008645890629850328\n",
      "step: 56, cost: 0.0003488383663352579\n",
      "step: 57, cost: 0.0006581484340131283\n",
      "step: 58, cost: 0.0009325805585831404\n",
      "step: 59, cost: 0.0007905904785729945\n",
      "step: 60, cost: 0.0009163404465653002\n",
      "step: 61, cost: 0.000684772094246\n",
      "step: 62, cost: 0.0007486941176466644\n",
      "step: 63, cost: 0.0010006228694692254\n",
      "step: 64, cost: 0.000877036654856056\n",
      "step: 65, cost: 0.0012878049165010452\n",
      "step: 66, cost: 0.0008949157781898975\n",
      "step: 67, cost: 0.0005999100976623595\n",
      "step: 68, cost: 0.00036450050538405776\n",
      "step: 69, cost: 0.0010081517975777388\n",
      "step: 70, cost: 0.001870479667559266\n",
      "step: 71, cost: 0.00043005638872273266\n",
      "step: 72, cost: 0.0010312212398275733\n",
      "step: 73, cost: 0.0005961284623481333\n",
      "step: 74, cost: 0.0012222382938489318\n",
      "step: 75, cost: 0.0010585678974166512\n",
      "step: 76, cost: 0.0011504709254950285\n",
      "step: 77, cost: 1.7563356777827721e-06\n",
      "step: 78, cost: 0.0006410886417143047\n",
      "step: 79, cost: 0.0007585517014376819\n",
      "step: 80, cost: 0.000721940363291651\n",
      "step: 81, cost: 0.0005527246976271272\n",
      "step: 82, cost: 0.0005534515366889536\n",
      "step: 83, cost: 0.0006750300526618958\n",
      "step: 84, cost: 0.0001874723966466263\n",
      "step: 85, cost: 0.0006025949260219932\n",
      "step: 86, cost: 0.0004927547997795045\n",
      "step: 87, cost: 0.0007070684805512428\n",
      "step: 88, cost: 0.000535611470695585\n",
      "step: 89, cost: 0.00043431963422335684\n",
      "step: 90, cost: 0.0004791079554706812\n",
      "step: 91, cost: 0.000564518035389483\n",
      "step: 92, cost: 0.0007010112749412656\n",
      "step: 93, cost: 0.0003797221288550645\n",
      "step: 94, cost: 0.000403872923925519\n",
      "step: 95, cost: 0.00040390377398580313\n",
      "step: 96, cost: 0.0007559211808256805\n",
      "step: 97, cost: 0.0004065964894834906\n",
      "step: 98, cost: 0.0005308155086822808\n",
      "step: 99, cost: 0.0004391903057694435\n",
      "step: 100, cost: 0.0006698690121993423\n",
      "step: 101, cost: 0.0006054037366993725\n",
      "step: 102, cost: 0.0004970572772435844\n",
      "step: 103, cost: 0.0006207006517797709\n",
      "step: 104, cost: 0.0005145618342794478\n",
      "step: 105, cost: 0.0006970995455048978\n",
      "step: 106, cost: 0.0007887541432864964\n",
      "step: 107, cost: 2.1671553440683056e-13\n",
      "step: 108, cost: 0.0013166371500119567\n",
      "step: 109, cost: 0.0009375865920446813\n",
      "step: 110, cost: 0.0006760022952221334\n",
      "step: 111, cost: 0.0005252427654340863\n",
      "step: 112, cost: 0.0008375285542570055\n",
      "step: 113, cost: 0.0008488232269883156\n",
      "step: 114, cost: 0.0008534740190953016\n",
      "step: 115, cost: 0.0008528465405106544\n",
      "step: 116, cost: 0.000619283935520798\n",
      "step: 117, cost: 0.0007677060784772038\n",
      "step: 118, cost: 0.0007752556120976806\n",
      "step: 119, cost: 0.001001135678961873\n",
      "step: 120, cost: 0.0012198570184409618\n",
      "step: 121, cost: 0.0009503462351858616\n",
      "step: 122, cost: 0.0005390184815041721\n",
      "step: 123, cost: 0.0007720238645561039\n",
      "step: 124, cost: 0.0004957080818712711\n",
      "step: 125, cost: 0.0006917053833603859\n",
      "step: 126, cost: 0.0008561757276766002\n",
      "step: 127, cost: 0.0006184768280945718\n",
      "step: 128, cost: 0.0015487743075937033\n",
      "step: 129, cost: 0.0007661686395294964\n",
      "step: 130, cost: 0.0006757469964213669\n",
      "step: 131, cost: 0.0008303361828438938\n",
      "step: 132, cost: 0.0006728023290634155\n",
      "step: 133, cost: 0.0006548296078108251\n",
      "step: 134, cost: 0.0006089677335694432\n",
      "step: 135, cost: 0.0002630357048474252\n",
      "step: 136, cost: 0.0007278372067958117\n",
      "step: 137, cost: 0.0009363560820929706\n",
      "step: 138, cost: 0.0006340646650642157\n",
      "step: 139, cost: 0.0007356372661888599\n",
      "step: 140, cost: 0.0014486153377220035\n",
      "step: 141, cost: 0.000560667656827718\n",
      "step: 142, cost: 0.0009980646427720785\n",
      "step: 143, cost: 0.0010020181071013212\n",
      "step: 144, cost: 0.0006885180482640862\n",
      "step: 145, cost: 0.0004139260563533753\n",
      "step: 146, cost: 0.0004917824408039451\n",
      "step: 147, cost: 0.0016912721330299973\n",
      "step: 148, cost: 0.0013923324877396226\n",
      "step: 149, cost: 0.001214022864587605\n",
      "step: 150, cost: 0.0005971539649181068\n",
      "step: 151, cost: 0.0008473508642055094\n",
      "step: 152, cost: 0.0005809202557429671\n",
      "step: 153, cost: 0.0005257751909084618\n",
      "step: 154, cost: 0.001203597872518003\n",
      "step: 155, cost: 0.0002838349319063127\n",
      "step: 156, cost: 0.0013913576258346438\n",
      "step: 157, cost: 0.0016344297910109162\n",
      "step: 158, cost: 0.0015536423306912184\n",
      "step: 159, cost: 0.0007756605045869946\n",
      "step: 160, cost: 0.001256065908819437\n",
      "step: 161, cost: 0.0003423071757424623\n",
      "step: 162, cost: 0.0006931736133992672\n",
      "step: 163, cost: 0.001290637068450451\n",
      "step: 164, cost: 0.000920580409001559\n",
      "step: 165, cost: 0.0030127400532364845\n",
      "step: 166, cost: 0.001175060635432601\n",
      "step: 167, cost: 0.0014795507304370403\n",
      "step: 168, cost: 0.0006328822928480804\n",
      "step: 169, cost: 0.0007576755597256124\n",
      "step: 170, cost: 0.00042469112668186426\n",
      "step: 171, cost: 0.0003066193894483149\n",
      "step: 172, cost: 0.0005415977793745697\n",
      "step: 173, cost: 0.0009600156918168068\n",
      "step: 174, cost: 0.0012624789960682392\n",
      "step: 175, cost: 0.0017463128315284848\n",
      "step: 176, cost: 0.0004531281301751733\n",
      "step: 177, cost: 0.00029776853625662625\n",
      "step: 178, cost: 0.0006823009462095797\n",
      "step: 179, cost: 0.0011749290861189365\n",
      "step: 180, cost: 0.0011406445410102606\n",
      "step: 181, cost: 0.0014225124614313245\n",
      "step: 182, cost: 0.0008893943740986288\n",
      "step: 183, cost: 0.0006110896938480437\n",
      "step: 184, cost: 0.001981934765353799\n",
      "step: 185, cost: 0.002344470703974366\n",
      "step: 186, cost: 0.0014048244338482618\n",
      "step: 187, cost: 0.001675020670518279\n",
      "step: 188, cost: 0.0017705963691696525\n",
      "step: 189, cost: 0.0019158788491040468\n",
      "step: 190, cost: 0.0024316541384905577\n",
      "step: 191, cost: 0.0012704480905085802\n",
      "step: 192, cost: 0.0016380061861127615\n",
      "step: 193, cost: 0.0019170551095157862\n",
      "step: 194, cost: 0.0018322925316169858\n",
      "step: 195, cost: 0.001689214026555419\n",
      "step: 196, cost: 0.0016605613054707646\n",
      "step: 197, cost: 0.0017574373632669449\n",
      "step: 198, cost: 0.0010900426423177123\n",
      "step: 199, cost: 0.0017821057699620724\n"
     ]
    }
   ],
   "source": [
    "cost_graph = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter('../temp/graph/graph_summary')\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    print('Learning started.')\n",
    "    for i in range(521):  #Batch number\n",
    "        Batch_size = len(Batch_LE_gaze_data)\n",
    "        for j in range(Batch_size):\n",
    "            feed_dict = {X_right: Batch_RE_img_data[i],X_left: Batch_LE_img_data[i],\n",
    "                         X_gaze_r:Batch_RE_gaze_data[i], X_gaze_l:Batch_LE_gaze_data[i],\n",
    "                         X_pose_r:Batch_RE_pose_data[i], X_pose_l:Batch_LE_pose_data[i],\n",
    "                         Y:Batch_label[i], keep_prob: 0.7}\n",
    "            s, _ = sess.run([summary, optimizer], feed_dict=feed_dict)\n",
    "            c = sess.run(cost, feed_dict=feed_dict)\n",
    "            cost_graph.append(c)\n",
    "        writer.add_summary(s, global_step=i)\n",
    "        print('step: {0}, cost: {1}'.format(i, c))\n",
    "        save_path = saver.save(sess,'../temp/variables/tensor_variables.ckpt') \n",
    "        \n",
    "        \n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cost_graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
