{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda-python\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import matplotlib.cm as cm\n",
    "from scipy.misc import imresize\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import scipy.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extraction(path):\n",
    "    data_l, data_r, data_all = [], [], []\n",
    "    nor_data = io.loadmat(path)\n",
    "    temp = nor_data['data']\n",
    "    r = temp['right']\n",
    "    l = temp['left']\n",
    "    r_temp = r[0,0]\n",
    "    l_temp = l[0,0]\n",
    "    data_r.append(r_temp['image'][0][0])\n",
    "    data_r.append(r_temp['gaze'][0][0])\n",
    "    data_r.append(r_temp['pose'][0][0])\n",
    "    data_l.append(l_temp['image'][0][0])\n",
    "    data_l.append(l_temp['gaze'][0][0])\n",
    "    data_l.append(l_temp['pose'][0][0])\n",
    "    for i in range(3):\n",
    "        data_all.append(data_r[i])   #0 -> r_img, 1-> l_img, 2-> r_gaze, 3->l_gaze..\n",
    "        data_all.append(data_l[i])\n",
    "    return data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_extraction(path, screen_path):\n",
    "    txt = pd.read_csv(path, sep = ' ', header= None)\n",
    "    screen = io.loadmat(screen_path)\n",
    "    df_anno = pd.DataFrame(txt)\n",
    "    data_frame = pd.DataFrame()\n",
    "    data_frame['Screen_x'] = df_anno[:][24] / screen['width_pixel'][0][0]\n",
    "    data_frame['Screen_y'] = df_anno[:][25] / screen['height_pixel'][0][0]\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_test = data_extraction('C:/MPIIGaze/MPIIGaze/Data/Normalized/p00/day01.mat')\n",
    "label_text = label_extraction('C:/MPIIGaze/MPIIGaze/Data/Original/p00/day01/annotation.txt',\n",
    "                             'C:/MPIIGaze/MPIIGaze/Data/Original/p00/Calibration/screenSize.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 60)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_img_label(image_shape, label_shape, data_list, label_list):\n",
    "    length = len(data_list[0])\n",
    "    left_img = np.zeros([length,image_shape])\n",
    "    right_img = np.zeros([length,image_shape])\n",
    "    label = np.zeros([length,label_shape])\n",
    "    for n in range(length):\n",
    "        left_img[n, :] = data_list[1][n].reshape(image_shape)\n",
    "        right_img[n, :] = data_list[0][n].reshape(image_shape)\n",
    "        label[n, :] = [label_list['Screen_x'][n], label_list['Screen_y'][n]]\n",
    "        \n",
    "    return right_img, left_img, label\n",
    "\n",
    "def make_dataset_gaze_pose(data_shape, data_list):\n",
    "    length = len(data_list[0])\n",
    "    left_pose = np.zeros([length,data_shape])\n",
    "    right_pose = np.zeros([length,data_shape])\n",
    "    left_gaze = np.zeros([length,data_shape])\n",
    "    right_gaze = np.zeros([length,data_shape])\n",
    "    for n in range(length):\n",
    "        left_gaze[n, :] = data_list[3][n]\n",
    "        right_gaze[n, :] = data_list[2][n]\n",
    "        left_pose[n, :] = data_list[5][n]\n",
    "        right_pose[n, :] = data_list[4][n]\n",
    "    return left_gaze, right_gaze, left_pose, right_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_img_data, LE_img_data, dataset_label = make_dataset_img_label(36 * 60, 2, data_test, label_text)\n",
    "LE_gaze_data, RE_gaze_data, LE_pose_data, RE_pose_data = make_dataset_gaze_pose(3, data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make graph for eye images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_for_image(X_img, keep_prob, name):\n",
    "    W1 = tf.Variable(tf.random_normal([4, 4, 1, 5], stddev=0.01))\n",
    "    L1 = tf.nn.conv2d(X_img, W1, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    L1 = tf.nn.relu(L1)\n",
    "\n",
    "    print(L1)\n",
    "\n",
    "    W2 = tf.Variable(tf.random_normal([2, 2, 5, 10], stddev=0.01))\n",
    "    L2 = tf.nn.conv2d(L1, W2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    L2 = tf.nn.relu(L2)\n",
    "    L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "    L2_flat = tf.reshape(L2, [-1, 5 * 8 * 10])\n",
    "    \n",
    "    print(\"'L2's shape\",L2.shape)\n",
    "    print(L2_flat)\n",
    "\n",
    "\n",
    "    W3 = tf.get_variable(\"W3_\"+name ,shape= [400, 256],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "    b3 = tf.Variable(tf.random_normal([256]))\n",
    "    L3 = tf.nn.relu(tf.matmul(L2_flat, W3) + b3)\n",
    "    L3 = tf.nn.dropout(L3, keep_prob= keep_prob)\n",
    "\n",
    "    print(L3.shape)\n",
    "\n",
    "    W4 = tf.get_variable(\"W4_\"+name ,shape= [256, 128],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "    b4 = tf.Variable(tf.random_normal([128]))\n",
    "    L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "    L4 = tf.nn.dropout(L4, keep_prob= keep_prob)\n",
    "    \n",
    "    W5 = tf.get_variable(\"W5_\"+name ,shape= [128, 64],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "    b5 = tf.Variable(tf.random_normal([64]))\n",
    "    logits = tf.matmul(L4, W5) + b5\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make graph for other datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_for_others(X, name):\n",
    "    W1 = tf.get_variable(\"W1_\"+name ,shape= [3, 3],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "    b1 = tf.Variable(tf.random_normal([3]))\n",
    "    L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "    print(L1.shape)\n",
    "\n",
    "    W2 = tf.get_variable(\"W2_\"+name ,shape= [3, 3],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "    b2 = tf.Variable(tf.random_normal([3]))\n",
    "    logits = tf.matmul(L1, W2) + b2\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define variable and make graphs using function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/spow12/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Tensor(\"Relu:0\", shape=(?, 18, 30, 5), dtype=float32)\n",
      "'L2's shape (?, 5, 8, 10)\n",
      "Tensor(\"Reshape_2:0\", shape=(?, 400), dtype=float32)\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-7-0c7719e4292b>:23: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "(?, 256)\n",
      "Tensor(\"Relu_4:0\", shape=(?, 18, 30, 5), dtype=float32)\n",
      "'L2's shape (?, 5, 8, 10)\n",
      "Tensor(\"Reshape_3:0\", shape=(?, 400), dtype=float32)\n",
      "(?, 256)\n",
      "(?, 3)\n",
      "(?, 3)\n",
      "(?, 3)\n",
      "(?, 3)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "Y = tf.placeholder(tf.float32, [None, 2])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "X_left = tf.placeholder(tf.float32, [None, 2160])\n",
    "X_right = tf.placeholder(tf.float32, [None, 2160])\n",
    "X_img_left = tf.reshape(X_left, [-1, 36, 60, 1])   \n",
    "X_img_right = tf.reshape(X_right, [-1, 36, 60, 1]) \n",
    "\n",
    "X_gaze_r = tf.placeholder(tf.float32, [None, 3])\n",
    "X_gaze_l = tf.placeholder(tf.float32, [None, 3])\n",
    "X_pose_r = tf.placeholder(tf.float32, [None, 3])\n",
    "X_pose_l = tf.placeholder(tf.float32, [None, 3])\n",
    "\n",
    "LE_img = model_for_image(X_img_left, keep_prob, 'left_eye')  #left eye imgae\n",
    "RE_img = model_for_image(X_img_right, keep_prob, 'right_eye')#right eye image\n",
    "LE_pose = model_for_others(X_pose_l, 'left_pose')\n",
    "LE_gaze = model_for_others(X_gaze_l, 'left_gaze')\n",
    "RE_pose = model_for_others(X_pose_r, 'right_pose')\n",
    "RE_gaze = model_for_others(X_gaze_r, 'right_gaze')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate the gaze graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LE_gaze_W = tf.get_variable(\"LE_gaze_W\" ,shape= [3, 3],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "RE_gaze_W = tf.get_variable(\"RE_gaze_W\" ,shape= [3, 3],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "layer_gaze = tf.nn.relu(tf.matmul(LE_gaze, LE_gaze_W) + tf.matmul(RE_gaze, RE_gaze_W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate the pose layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LE_pose_W = tf.get_variable(\"LE_pose_W\" ,shape= [3, 3],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "RE_pose_W = tf.get_variable(\"RE_pose_W\" ,shape= [3, 3],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "layer_pose = tf.nn.relu(tf.matmul(LE_pose, LE_pose_W) + tf.matmul(RE_pose, RE_pose_W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate the Image layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LE_W_img = tf.get_variable(\"LE_W_img\" ,shape= [64, 32],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "RE_W_img = tf.get_variable(\"RE_W_img\" ,shape= [64, 32],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "layer_img = tf.nn.relu(tf.matmul(LE_img, LE_W_img) + tf.matmul(RE_img, RE_W_img))\n",
    "\n",
    "img_W = tf.get_variable(\"img_W\" ,shape= [32, 16],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "img_b = tf.Variable(tf.random_normal([16]))\n",
    "layer2_img = tf.nn.relu(tf.matmul(layer_img, img_W) + img_b)\n",
    "\n",
    "img_W2 = tf.get_variable(\"img_W2\" ,shape= [16, 8],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "img_b2 = tf.Variable(tf.random_normal([8]))\n",
    "layer3_img= tf.nn.relu(tf.matmul(layer2_img, img_W2) + img_b2)\n",
    "\n",
    "Final_W_img = tf.get_variable(\"Final_W_img\" ,shape= [8, 3],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "Final_b_img = tf.Variable(tf.random_normal([3]))\n",
    "Final_layer_img= tf.nn.relu(tf.matmul(layer3_img, Final_W_img) + Final_b_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight and bias for img layer\n",
    "All_W_img = tf.get_variable(\"All_W_img\" ,shape= [3, 2],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "# Weight and bias for pose layer\n",
    "All_W_pose = tf.get_variable(\"All_W_pose\" ,shape= [3, 2],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "# Weight and bias for gaze layer\n",
    "All_W_gaze = tf.get_variable(\"All_W_gaze\" ,shape= [3, 2],\n",
    "                         initializer= tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "\n",
    "logits = (tf.matmul(Final_layer_img, All_W_img) \n",
    "          + tf.matmul(layer_pose, All_W_pose)\n",
    "          + tf.matmul(layer_gaze, All_W_gaze))\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(logits-Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "step: 0, cost: 11.38553524017334\n",
      "step: 100, cost: 0.6470407247543335\n",
      "step: 200, cost: 0.21433332562446594\n",
      "step: 300, cost: 0.18179911375045776\n",
      "step: 400, cost: 0.14216668903827667\n",
      "step: 500, cost: 0.09956863522529602\n",
      "step: 600, cost: 0.08182694762945175\n",
      "step: 700, cost: 0.07897178083658218\n",
      "step: 800, cost: 0.07836045324802399\n",
      "step: 900, cost: 0.07815288752317429\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning started. It takes sometime.')\n",
    "for i in range(len(RE_img_data)):\n",
    "    feed_dict = {X_right: RE_img_data,X_left: LE_img_data,\n",
    "                 X_gaze_r:RE_gaze_data, X_gaze_l:LE_gaze_data,\n",
    "                 X_pose_r:RE_pose_data, X_pose_l:LE_pose_data,\n",
    "                 Y:dataset_label, keep_prob: 0.8}\n",
    "    c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "    if i % 100 == 0:\n",
    "         print('step: {0}, cost: {1}'.format(i, c))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
