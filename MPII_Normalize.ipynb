{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import matplotlib.cm as cm\n",
    "from scipy.misc import imresize\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import scipy.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116b1eaa160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the face model\n",
    "facemodel_mat = io.loadmat('C:/Users/nam young woo/Downloads/Codes/Eye Tracking/Codes/MPIIGaze/6 points-based face model.mat')\n",
    "facemodel = facemodel_mat['model']\n",
    "# I have to know about 6 points-based face model\n",
    "\n",
    "# load the image, annotation and camera parameters.\n",
    "img=cv2.imread('C:/Users/nam young woo/Downloads/Codes/Eye Tracking/Codes/MPIIGaze/Data/Original/p00/day01/0001.jpg')\n",
    "anotation_df = pd.read_csv('C:/Users/nam young woo/Downloads/Codes/Eye Tracking/Codes/MPIIGaze/Data/Original/p00/day01/annotation.txt',sep = ' ' ,header= None)\n",
    "anotation = np.array(anotation_df)\n",
    "cameraCalib_mat = io.loadmat('C:/Users/nam young woo/Downloads/Codes/Eye Tracking/Codes/MPIIGaze/Data/Original/p00/Calibration/Camera.mat')\n",
    "\n",
    "#get head pose\n",
    "headpose_hr = anotation[0][29:32]\n",
    "headpose_ht = anotation[0][32:35]\n",
    "hR = cv2.Rodrigues(headpose_hr)[0]\n",
    "Fc = np.dot(hR ,facemodel) #rotate the face model, which is calcluated from facial landmakr detection\n",
    "try:\n",
    "    Fc[0] = Fc[0] + headpose_ht[0]\n",
    "    Fc[1] = Fc[1] + headpose_ht[1]\n",
    "    Fc[2] = Fc[2] + headpose_ht[2]\n",
    "except ValueError:\n",
    "    print(\"Fc shape and headpose_ht isn't same!\")\n",
    "    pass\n",
    "\n",
    "# get the eye center in the original camera cooridnate system.\n",
    "right_eye_cetter= 0.5 * (Fc[:, 0] + Fc[:, 1])\n",
    "left_eye_center = 0.5 * (Fc[:, 2] + Fc[:, 3])\n",
    "\n",
    "# get the gaze target\n",
    "gaze_target= anotation[0, 26:29]\n",
    "gaze_target = gaze_target.transpose()\n",
    "\n",
    "# set the size of normalized eye image\n",
    "eye_image_width=60\n",
    "eye_image_height=36\n",
    "\n",
    "# normalization for the right eye, you can do it for left eye by replacing\n",
    "# \"right_eye_cetter\" to \"left_eye_center\"\n",
    "\n",
    "eye_img,headpose,gaze=normalizeImg(img,right_eye_cetter,hR,gaze_target,\n",
    "                                   [eye_image_width, eye_image_height],\n",
    "                                   cameraCalib['cameraMatrix'])\n",
    "\n",
    "plt.imshow(eye_img)\n",
    "\n",
    "# convert the gaze direction in the camera cooridnate system to the angle\n",
    "# in the polar coordinate system\n",
    "\n",
    "gaze_theta= np.arcsin(-1 * gaze[1])\n",
    "gaze_phi= np.arctan2((-1 * gaze[0]), -1 * gaze[2])\n",
    "\n",
    "\n",
    "# save as above, conver head pose to the polar coordinate system\n",
    "M = cv2.Rodrigues(headpose)[0]\n",
    "Zv= M[:, 2]\n",
    "headpose_theta= np.arcsin(Zv[1])\n",
    "headpose_phi= np.arctan2(Zv[0], Zv[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeImg(inputImg, target_3D, hR, gc, roiSize, cameraMatrix, *args):\n",
    "    \n",
    "    nargin = len(args)\n",
    "    # prepare the data\n",
    "    # for right eye\n",
    "    if nargin < 8:\n",
    "        focal_new=960  #facoal length of the virual camera can be changed as needed.\n",
    "    if nargin < 9:\n",
    "        distance_new=600 \n",
    "# please do not change it or set it to be different value, otherwise the gaze label will be different.\n",
    "    \n",
    "    distance= np.linalg.norm(gaze_target)\n",
    "    z_scale=distance_new / distance\n",
    "    cam_new= np.array([[focal_new, 0, roiSize[0] / 2], [0.0, focal_new, roiSize[1] /2],  [0, 0, 1.0]])\n",
    "    scaleMat= np.array([[1.0,0.0,0.0],[0.0,1.0,0.0],[0.0,0.0,z_scale]])\n",
    "    hRx=hR[:,0]\n",
    "    forward =(target_3D / distance)\n",
    "    down = np.cross(forward,hRx)\n",
    "    down = down / np.linalg.norm(down)\n",
    "    right = np.cross(down,forward)\n",
    "    right=right / np.linalg.norm(right)\n",
    "    rotMat = np.array([right, down, forward]).transpose()\n",
    "    \n",
    "    warpMat = np.matmul(np.matmul(cam_new, scaleMat), np.matmul(rotMat, np.linalg.inv(cameraMatrix)));\n",
    "    img_warped= cv2.warpPerspective(inputImg,warpMat, (roiSize[0], roiSize[1]))\n",
    "    # ROI size can be error?\n",
    "    \n",
    "    # rotatoin normalization\n",
    "    cnvMat= np.matmul(scaleMat,rotMat)\n",
    "    hRnew = np.matmul(cnvMat, hR)\n",
    "    hrnew = cv2.Rodrigues(hRnew)[0]\n",
    "    htnew= np.matmul(cnvMat,target_3D)\n",
    "    \n",
    "    # gaze vector normalizatoin\n",
    "    gcnew= np.matmul(cnvMat,gc)\n",
    "    gvnew= gcnew - htnew\n",
    "    gvnew= gvnew / np.linalg.norm(gvnew)\n",
    "    return img_warped,hrnew,gvnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
